\section{Introduction}
Hyperbolic equations play an important role in various research areas such as fluid dynamics or plasma physics. Efficient numerical methods combined with robust implementations are available for these problems, however they do not account for uncertainties which can arise in measurement data or modeling assumptions. Including the effects of uncertainties in differential equations has become an important topic in the last decades. %Examples include computational fluid dynamics \cite{bijl2013uncertainty}. 

A general hyperbolic set of equations with random initial data can be written as
\begin{subequations}\label{eq:hyperbolicProblem}
\begin{align}
\partial_t \bm{u}(t,\bm{x},\bm{\xi}) + \nabla&\cdot\bm{F}(\bm{u}(t,\bm{x},\bm{\xi})) = \bm{0}, \\ \label{eq:ic}
\bm{u}(t=0,\bm{x},&\bm{\xi}) = \bm{u}_{\text{IC}}(\bm{x},\bm{\xi}),
\end{align}
\end{subequations}
where the solution $u\in\mathbb{R}^p$ depends on time $t\in\mathbb{R}^+$, spatial position $\bm{x}\in D\subset \mathbb{R}^d$ as well as a vector of random variables $\bm{\xi}\in\Theta\subset\mathbb{R}^s$ with given probability density functions $f_{\Xi,i}(\xi_i)$ for $i = 1,\cdots,s$. The physical flux is given by $\bm{F}:\mathbb{R}^p\to\mathbb{R}^p$. To simplify notation, we assume that the initial condition is random, i.e. $\bm{\xi}$ enters through the definition of $\bm{u}_{IC}$. Equations \eqref{eq:hyperbolicProblem} are usually supplemented with boundary conditions, which we will specify later for the individual problems.

Due to the randomness of the solution, one is interested in determining the expectation value or the variance of the solution, i.e.
\begin{align*}
\text{E}[\bm{u}] = \langle \bm{u} \rangle,\qquad \text{Var}[\bm{u}] = \langle \left( \bm{u}-\text{E}[\bm{u}]\right)^2\rangle,
\end{align*}
where we use the bracket operator $\langle \cdot \rangle := \int_{\Theta} \cdot \prod_{i=1}^s f_{\Xi,i}(\xi_i)d\xi_1 \cdots d\xi_s$. More generally, one is interested in determining the moments of the solution for a given set of orthonormal basis functions $\varphi_{i}:\Theta\to\mathbb{R}$ such that for the multi-index $i = (i_1,\cdots,i_s)$ we have $|i| \leq N$. The moments are then given by $\bm{\hat u_i} := \langle \bm{u}\varphi_i \rangle$.\\

Numerical methods for approximating the moment $\bm{\hat u_i}$ can be divided into intrusive and non-intrusive methods. A popular non-intrusive method is the stochastic-Collocation (SC) method, which computes the moments with the help of a numerical quadrature rule: For a given set of $N_q$ quadrature weights $w_k$ and quadrature points $\bm{\xi}_k$, the moments are approximated by
\begin{align*}
\bm{\hat u_i} = \langle \bm{u}\varphi_i \rangle \approx \sum_{k = 1}^{N_q}w_k \bm{u}({t,\bm{x},\bm{\xi}_k})\varphi_i(\bm{\xi_k})f_{\Xi}(\bm{\xi}_k).
\end{align*} 
Since the solution at a fixed quadrature point can be computed by a standard deterministic solver, the SC method does not require a big implementation effort. Furthermore, it is embarrassingly parallel, since the required computations can be carried out in parallel on different cores. A downside of collocation methods are aliasing effects, which stem from the inexact approximation of the integral. Furthermore, collocation methods require more runs of the deterministic solver than intrusive methods \cite{xiu2009fast,alekseev2011estimation}. Despite their easy implementation, collocation methods can become cumbersome for unsteady problems, since in this case, the solution needs to written out at all quadrature points in every time step to compute the time evolution of the moments.
This problem does not occur in intrusive methods, since the computation is carried out on the moments, i.e. the time evolution can be recorded during the computation. Also for steady problems, the fact that the computation is carried out on the moments provided the ability to compute the stochastic residual, which indicates when to stop the iteration towards the steady state solution. However intrusive methods are in general more difficult to implement and come with higher numerical costs. The main idea of these methods is to derive a system of equations for the moments and implementing a numerical solver for this system: Testing the initial problem \eqref{eq:hyperbolicProblem} with $\varphi_i$ for $|i|\leq M$ yields
\begin{subequations}\label{eq:nonClosedMomentSystem}
\begin{align}
\partial_t \bm{\hat u}_i(t,\bm{x}) + \nabla&\cdot\langle\bm{F}(\bm{u}(t,\bm{x},\cdot)) \varphi_i\rangle = \bm{0}, \\
\bm{\hat u_i}(t=0,\bm{x}&) = \langle\bm{u}_{\text{IC}}(\bm{x},\cdot)\varphi_i\rangle.
\end{align}
\end{subequations}
To obtain a closed set of equations, one needs to derive a closure $\mathcal{U}$ such that 
\begin{align*}
\bm{u}(t,\bm x,\bm \xi) \approx \mathcal{U}(\bm{\hat u}_0,\cdots,\bm{\hat u}_N;\xi).
\end{align*}
A commonly used closure is the stochastic-Galerkin, which represents the solution by a polynomial:
\begin{align*}
\mathcal{U}_{\text{SG}}(\bm{\hat u}_0,\cdots,\bm{\hat u}_N;\xi):= \sum_{i=0}^N \bm{\hat{u}}_i\varphi_i(\bm{\xi}).
\end{align*}
When using the stochastic-Galerkin method to close \eqref{eq:nonClosedMomentSystem}, the resulting moment system is not necessarily hyperbolic, meaning that it cannot be solved with standard methods. An approach to derive a closure, which ensures hyperbolicity is the Intrusive Polynomial Moment (IPM) closure, which has been presented in \cite{poette2009uncertainty}: The closure is given by a constraint optimization problem. For a given convex entropy $s:\mathbb{R}^p\to\mathbb{R}$ for the original problem \eqref{eq:hyperbolicProblem}, this optimization problem is
\begin{align}\label{eq:primalProblem}
\mathcal{U}_{ME}(\bm{u}) = \argmin_{\bm u} \langle s(\bm u) \rangle \enskip \text{ subject to } \bm{\hat u}_i = \langle \bm u \varphi_i \rangle \text{ for } i = 0,\cdots,N.
\end{align}
This problem can be rewritten as
\begin{align}\label{eq:dualProblem}
 \bm{\hat \lambda}(\bm{\hat u}) := \argmin_{\bm{\lambda} \in \mathbb{R}methods^{s\cdot(N + 1)}}
  \left\{\langle s_*(\sum_{i=0}^{N}\bm{\lambda}_i \varphi_i)\rangle - \sum_{i=0}^{N}\bm{\lambda}_i^T \bm{\hat u}_i\right\},
\end{align}
where $s_*:\mathbb{R}^p\to\mathbb{R}$ is the Legendre transformation of $s$, and $\bm{ \hat\lambda}$ are called the dual variables. The solution to \eqref{eq:primalProblem} is then given by
\begin{align}\label{eq:ansatz}
 \mathcal{U}_{ME}(\bm{\hat u}) = \left( s_{\bm{\hat u}} \right)^{-1}(\bm{\hat{\lambda}}(\bm{u})^T \bm{\varphi}).
\end{align}
Plugging the derived closure into the moment system \eqref{eq:nonClosedMomentSystem}, one obtains the IPM moment system
\begin{subequations}\label{eq:IPMmomentSystem}
\begin{align}
\partial_t \bm{\hat u}_i(t,\bm{x}) + \nabla&\cdot\langle\bm{F}(\mathcal{U}_{ME}(\bm{\hat u})) \varphi_i\rangle = \bm{0}, \\
\bm{\hat u_i}(t=0,\bm{x}&) = \langle\bm{u}_{\text{IC}}(\bm{x},\cdot)\varphi_i\rangle.
\end{align}
\end{subequations}
The IPM method has several advantages: Choosing the entropy $s(\bm{u}) = \frac{1}{2}\bm{u}^T\bm{u}$ yields the stochastic-Galerkin method, i.e. IPM generalizes different intrusive method. Furthermore, at least for scalar problems, IPM is significantly less oscillatory compared to SG \cite{kusch2017maximum}. Also, as discussed in \cite{poette2009uncertainty}, when choosing $s(\bm u)$ to be a physically correct entropy of the deterministic problem, the IPM solution dissipates the entropy
\begin{align*}
S(\bm{\hat u}) := \langle s( \mathcal{U}_{ME}(\bm{\hat u}))\rangle,
\end{align*}
i.e. the IPM method yields a physically correct entropy solution. This again underlines a weakness of stochastic-Galerkin: If $s(\bm{u}) = \frac{1}{2}\bm{u}^T\bm{u}$ is not a correct entropy of the original problem, the SG method can lead to non-physical solution, which can then cause a failure of the method. The main weakness of the IPM method is its run time, since it requires the repeated evaluation of \eqref{eq:ansatz}, which involves the computation of the optimization problem \eqref{eq:dualProblem}. Hence, the desirable costs of IPM (and intrusive methods in general) require a significantly increased run time. A further advantages which we will not use in this work is the possibility of using adaptivity \cite{kroker2012finite}, i.e. refining the stochastic space at certain spatial position and time steps in which complex structures such as discontinuities occur. The main task here is to find an adequate refinement indicator \cite{kroker2012finite,giesselmann2017posteriori}.\\

In this paper, we present a semi-intrusive code framework, which facilitates the task of implementing general intrusive methods. The framework only requires the numerical flux of the deterministic problem. If IPM is used, the entropy of the deterministic problem needs to be provided. We thereby provide the ability to recycle existing implementations of deterministic solvers.
Furthermore, we investigate intrusive methods for steady problems and compare them to collocation methods. The steady setting provides different opportunities to take advantage of features of intrusive methods: 
\begin{itemize}
\item We propose to apply intrusive methods as a post-processing step for collocation methods: We converge the moments of the solution to a steady state with an inaccurate, but cheap collocation method and then use the resulting collocation moments as starting values for an expensive but accurate intrusive method, which we then again converge to steady state. 
\item Since the moments during the iteration process are inaccurate, i.e. they are not the steady state solution, we propose not fully converge the dual iteration, which computes \eqref{eq:dualProblem}. 
\end{itemize}

The paper is structured as follows: After 

