\section{One-Shot IPM}
\label{sec:OneShotIPM}

In the following section we only consider steady state problems, i.e. equation \eqref{eq:fulleq} reduces to
\begin{linenomath*}\begin{align}\label{eq:hyperbolicProblemSteady}
\nabla\cdot\bm{f}(\bm{u}(\bm{x},\bm{\xi})) = \bm{0} \enskip \text{ in } D
\end{align}\end{linenomath*}
with adequate boundary conditions. A general strategy for computing the steady state solution to \eqref{eq:hyperbolicProblemSteady} is to introduce a pseudo-time and numerically treat \eqref{eq:hyperbolicProblemSteady} as an unsteady problem. A steady state solution is then obtained by iterating in pseudo-time until the solution remains constant. It is important to point out that the time it takes to converge to a steady state solution is crucially affected by the chosen initial condition and its distance to the steady state solution.
Similar to the unsteady case \eqref{eq:hyperbolicProblem}, we can again derive a moment system for \eqref{eq:hyperbolicProblemSteady} given by
\begin{linenomath*}\begin{align}\label{eq:MomentSystemSteady}
\nabla\cdot\langle\bm{f}(\bm{u}(\bm{x},\bm{\xi}))\bm{\varphi}^T\rangle^T = \bm{0} \enskip \text{ in } D
\end{align}\end{linenomath*}
which is again needed for the construction of intrusive methods. By introducing a pseudo-time and using the IPM closure, we obtain the same system as in \eqref{eq:SGMomentSystem}, i.e. Algorithm \ref{alg:IPM} can be used to iterate to a steady state solution. Note that now, the time iteration is not performed for a fixed number of time steps $N_t$, but until the condition
\begin{linenomath*}\begin{align}\label{eq:residualSteady}
\sum_{j = 1}^{N_x} \Delta x_j \Vert \bm{\hat{u}}_j^n - \bm{\hat{u}}_j^{n-1} \Vert \leq \varepsilon
\end{align}\end{linenomath*}
is fulfilled. Condition \eqref{eq:residualSteady}, which is for example being used in the SU2 code framework \cite{economon2015su2}, measures the change of the solution by a single time iteration. Note, that in order to obtain an estimate of the distance to the steady state solution, one has to include the Lipschitz constant of the corresponding fixed point problem. Since one is generally interested in low order moments such as the expectation value, the residual \eqref{eq:residualSteady} can be modified by only accounting for the zero order moments.

In this section we aim at breaking up the inner loop in the IPM Algorithm \ref{alg:IPM}, i.e. to just perform one iteration of the dual problem in each time step. Consequently, the IPM reconstruction given by \eqref{eq:primalProblem} is not done exactly, meaning that the reconstructed solution does not minimize the entropy while not fulfilling the moment constraint. However, the fact that the moment vectors are not yet converged to the steady solution seems to permit such an inexact reconstruction. Hence, we aim at iterating the moments to steady state and the dual variables to the exact solution of the IPM optimization problem \eqref{eq:primalProblem} simultaneously.
By successively performing one update of the moment iteration and one update of the dual iteration, we obtain 
\begin{subequations}\label{eq:oneshotIPM}
\begin{linenomath*}\begin{align}
&\bm{\lambda}_{j}^{n+1} =  \bm{d}(\bm{\lambda}_j^{n},\bm{u}_j^{n}) \enskip \text{ for all }j \label{eq:oneshotIPMdual}\\
&\bm{u}_j^{n+1} =  \bm{c}\left(\bm{\lambda}_{j-1}^{n+1},\bm{\lambda}_{j}^{n+1},\bm{\lambda}_{j+1}^{n+1}\right) \enskip \text{ for all }j \label{eq:oneshotIPMmoment}.
\end{align}\end{linenomath*}
\end{subequations}
This yields Algorithm \ref{alg:osIPM}.
\begin{algorithm}[H]
\begin{algorithmic}[1]
\For{$j=0$ to $N_x+1$}
\State $\bm{u}_j^0 \leftarrow \frac{1}{\Delta x} \int_{x_{j-1/ 2}}^{x_{j+1/ 2}} \langle u_{\text{IC}}(x, \cdot) \bm{\varphi} \rangle_Q dx$
\EndFor
\While{\eqref{eq:residualSteady} is violated}
\For{$j=1$ to $N_x$}
\State $\bm{\lambda}_j^{n+1} \leftarrow \bm{d}(\bm{\lambda}_{j}^{n};\bm{\hat u}_j^{n})$
\EndFor
\For{$j=1$ to $N_x$}
\State $\bm{\hat u}_j^{n+1} \leftarrow \bm{c}(\bm{\lambda}_{j-1}^{n+1},\bm{\lambda}_j^{n+1},\bm{\lambda}_{j+1}^{n+1})$
\EndFor
\State $n \leftarrow n+1$
\EndWhile
\end{algorithmic}
\caption{One-Shot IPM implementation}
\label{alg:osIPM}
\end{algorithm}
We call this method One-Shot IPM, since it is inspired by One-Shot optimization, see for example \cite{hazra2005aerodynamic}, which uses only a single iteration of the primal and dual step in order to update the design variables. Note that the dual variables from the One-Shot IPM iteration are written without a hat to indicate that they are not the exact solution of the dual problem.

In the following, we will show that this iteration converges, if the chosen initial condition is sufficiently close to the steady state solution. For this we take an approach commonly chosen to prove local convergence properties of Newton's method: In Theorem \ref{th:Contractive}, we show that the iteration function is contractive at its fixed point and conclude in Theorem \ref{th:localConvergence} that this yields local convergence. Hence, we preserve the convergence property of the original IPM method, which uses Newton's method and therefore only converges locally as well.
\begin{theorem}\label{th:Contractive}
Assume that the classical IPM iteration is contractive at its fixed point $\bm{\hat u}^*$. Then the Jacobian $\bm{J}$ of the One-Shot IPM iteration \eqref{eq:oneshotIPM} has a spectral radius $\rho(\bm{J})<1$ at the fixed point $(\bm{\lambda}^*,\bm{\hat u}^*)$.
\end{theorem}
\begin{proof}
First, to understand what contraction of the classical IPM iteration implies, we rewrite the moment iteration \eqref{eq:momentIteration} of the classical IPM scheme: When defining the update function
\begin{linenomath*}\begin{align*}
\bm{\tilde c}\left(\bm{\hat{u}}_{\ell},\bm{\hat{u}}_{c},\bm{\hat{u}}_{r}\right):=\bm{c}\left(\bm{\hat{\lambda}}(\bm{\hat{u}}_{\ell}),\bm{\hat{\lambda}}(\bm{\hat{u}}_{c}),\bm{\hat{\lambda}}(\bm{\hat{u}}_{r})\right)
\end{align*}\end{linenomath*}
we can rewrite the classical moment iteration as
\begin{linenomath*}\begin{align}\label{eq:shortIPMIt}
\bm{\hat u}_j^{n+1} = \bm{\tilde c}\left(\bm{\hat u}_{j-1}^n,\bm{\hat u}_{j}^n,\bm{\hat u}_{j+1}^n\right).
\end{align}\end{linenomath*}
Since we assume that the classical IPM scheme is contractive at its fixed point, we have $\rho (\nabla_{\bm{\hat u}}\bm{\tilde c}(\bm{\hat u}^*))<1$ with $\nabla_{\bm{\hat u}}\bm{\tilde c}\in\mathbb{R}^{N\cdot N_x\times N\cdot N_x}$ defined by
\begin{linenomath*}\begin{align*}
\nabla_{\bm{\hat u}}\bm{\tilde c} = 
\begin{pmatrix} 
    \partial_{\bm{\hat u}_c}\bm{\tilde c}_{1} & \partial_{\bm{\hat u}_r}\bm{\tilde c}_{1}& 0 & 0 & \dots \\
    \partial_{\bm{\hat u}_{\ell}}\bm{\tilde c}_{2} & \partial_{\bm{\hat u}_c}\bm{\tilde c}_{2} & \partial_{\bm{\hat u}_r}\bm{\tilde c}_{2}& 0 & \dots \\
    0 & \partial_{\bm{\hat u}_{\ell}}\bm{\tilde c}_{3} & \partial_{\bm{\hat u}_c}\bm{\tilde c}_{3} & \partial_{\bm{\hat u}_r}\bm{\tilde c}_{3}\\
    \vdots & & & \ddots & \\
    0 &\cdots &  0 & \partial_{\bm{\hat u}_{\ell}}\bm{\tilde c}_{N_x} & \partial_{\bm{\hat u}_c}\bm{\tilde c}_{N_x}
    \end{pmatrix},
\end{align*}\end{linenomath*}
where we define $\bm{\tilde c}_{j}:=\bm{\tilde c}\left(\bm{\hat u}_{j-1}^*,\bm{\hat u}_{j}^*,\bm{\hat u}_{j+1}^*\right)$ for all $j$. Now for each term inside the matrix $\nabla_{\bm{\hat u}}\bm{\tilde c}$ we have 
\begin{linenomath*}\begin{align}\label{eq:cTildeDer}
\partial_{\bm{\hat u}_{\ell}}\bm{\tilde c}_{j} = \frac{\partial \bm{c}_j}{\partial \bm{\hat \lambda}_{\ell}}\frac{\partial \bm{\hat \lambda}(\bm{\hat u}_{j-1}^*)}{\partial \bm{\hat u}},\enskip\partial_{\bm{\hat u}_c}\bm{\tilde c}_{j} = \frac{\partial \bm{c}_j}{\partial \bm{\hat \lambda}_c}\frac{\partial \bm{\hat \lambda}(\bm{\hat u}_j^*)}{\partial \bm{\hat u}},\enskip\partial_{\bm{\hat u}_r}\bm{\tilde c}_{j} = \frac{\partial \bm{c}_j}{\partial \bm{\hat \lambda}_r}\frac{\partial \bm{\hat \lambda}(\bm{\hat u}_{j+1}^*)}{\partial \bm{\hat u}}.
\end{align}\end{linenomath*}
We first wish to understand the structure of the terms $\partial_{\bm{\hat u}} \bm{\hat \lambda}(\bm{\hat u})$. For this, we note that the exact dual variables fulfill
\begin{linenomath*}\begin{align}\label{eq:ulambda}
\bm{\hat u} = \langle \bm{u}_s(\bm{\hat \lambda}^T\bm{\varphi})\bm{\varphi}^T\rangle^T =: \bm{h}(\bm{\hat \lambda}),
\end{align}\end{linenomath*}
which is why we have the mapping $\bm{\hat u}:\mathbb{R}^{N\times m}\to\mathbb{R}^{N\times m}$, $\bm{\hat u}(\bm{\hat \lambda}) = \bm{h}(\bm{\hat \lambda})$. Since the solution of the dual problem for a given moment vector is unique, this mapping is bijective and therefore we have an inverse function
\begin{linenomath*}\begin{align}\label{eq:lambdau}
\bm{\hat \lambda} = \bm{h}^{-1}(\bm{\hat u}(\bm{\hat \lambda})).
\end{align}\end{linenomath*}
Now we differentiate both sides w.r.t. $\bm{\hat \lambda}$ to get
\begin{linenomath*}\begin{align*}
\bm{I}_{d} = \frac{\partial \bm{h}^{-1}(\bm{\hat u}(\bm{\hat \lambda}))}{\partial \bm{\hat u}}\frac{\partial \bm{\hat u}(\bm{\hat \lambda})}{\partial \bm{\hat \lambda}}.
\end{align*}\end{linenomath*}
We multiply with the matrix inverse of $\frac{\partial \bm{\hat u}(\bm{\hat \lambda})}{\partial \bm{\hat \lambda}}$ to get
\begin{linenomath*}\begin{align*}
\left(\frac{\partial \bm{\hat u}(\bm{\hat \lambda})}{\partial \bm{\hat \lambda}}\right)^{-1} = \frac{\partial \bm{h}^{-1}(\bm{\hat u}(\bm{\hat \lambda}))}{\partial \bm{\hat u}}.
\end{align*}\end{linenomath*}
Note that on the left-hand-side we have the inverse of a matrix and on the right-hand-side, we have the inverse of a multi-dimensional function. By rewriting $\bm{h}^{-1}(\bm{\hat u}(\bm{\hat \lambda}))$ as $\bm{\hat \lambda}(\bm{\hat u})$ and simply computing the term $\frac{\partial \bm{\hat u}(\bm{\hat \lambda})}{\partial \bm{\hat \lambda}}$ by differentiating \eqref{eq:ulambda} w.r.t. $\bm{\hat \lambda}$, one obtains
\begin{linenomath*}\begin{align}\label{eq:dudlambdaex}
\partial_{\bm{\hat u}} \bm{\hat \lambda}(\bm{\hat u}) = \langle \nabla\bm{u}_s(\bm{\hat \lambda}^T\bm{\varphi})\bm{\varphi}\bm{\varphi}^T\rangle^{-T}.
\end{align}\end{linenomath*}
Now we begin to derive the spectrum of the \textit{One-Shot IPM} iteration \eqref{eq:oneshotIPM}. Note that in its current form this iteration is not really a fixed point iteration, since it uses the time updated dual variables in \eqref{eq:oneshotIPMmoment}. To obtain a fixed point iteration, we plug the dual iteration step \eqref{eq:oneshotIPMdual} into the moment iteration \eqref{eq:oneshotIPMmoment} to obtain
\begin{linenomath*}\begin{align*}
&\bm{\lambda}_j^{n+1} = \bm{d}(\bm{\lambda}_j^{n},\bm{\hat u}_j^{n}) \enskip \text{ for all j} \\
&\bm{\hat u}_j^{n+1} =  \bm{c}\left(\bm{d}(\bm{\lambda}_{j-1}^{n},\bm{\hat u}_{j-1}^{n}),\bm{d}(\bm{\lambda}_{j}^{n},\bm{\hat u}_{j}^{n}),\bm{d}(\bm{\lambda}_{j+1}^{n},\bm{\hat u}_{j+1}^{n})\right).
\end{align*}\end{linenomath*}
The Jacobian $\bm{J}\in\mathbb{R}^{2N\cdot N_x \times 2N\cdot N_x}$ has the form
\begin{linenomath*}\begin{align}\label{eq:Jacobian}
\bm{J} = 
\begin{pmatrix}
 \partial_{\bm{\lambda}} \bm{d} & \partial_{\bm{\hat u}} \bm{d}  \\
\partial_{\bm{\lambda}} \bm{c} & \partial_{\bm{\hat u}} \bm{c}
\end{pmatrix},
\end{align}\end{linenomath*}
where each block has entries for all spatial cells. We start by looking at $\partial_{\bm{\lambda}} \bm{d}$. For the columns belonging to cell $j$, we have
\begin{linenomath*}\begin{align*}
\partial_{\bm{\lambda}} \bm{d}(\bm{\lambda}_j^n,\bm{\hat u}_j^n) &= \bm{I}_d - \bm{H}(\bm\lambda)^{-1} \cdot \langle \nabla\bm{u}_s(\bm{\varphi}^T\bm{\lambda}_j^n)\bm{\varphi}\bm{\varphi}^T \rangle^T - \partial_{\bm{\lambda}}\bm{H}(\bm\lambda)^{-1} \cdot \left( \langle \bm{u}_s(\bm{\varphi}^T\bm{\lambda}_j^n)\bm{\varphi}^T \rangle^T - \bm{\hat u}\right) \\
&=- \partial_{\bm{\lambda}}\bm{H}(\bm\lambda)^{-1} \cdot \left( \langle \bm{u}_s(\bm{\varphi}^T\bm{\lambda}_j^n)\bm{\varphi}^T \rangle^T - \bm{\hat u}\right).
\end{align*}\end{linenomath*}
Recall that at the fixed point $(\bm{\lambda}^*,\bm{\hat u}^*)$, we have $\langle \bm{u}_s(\bm{\varphi}^T\bm{\lambda}_j^n)\bm{\varphi}^T \rangle^T = \bm{\hat u}$, hence one obtains $\partial_{\bm{\lambda}} \bm{d}=\bm{0}$. For the block $\partial_{\bm{\hat u}} \bm{d}$, we get 
\begin{linenomath*}\begin{align*}
\partial_{\bm{\hat u}} \bm{d}(\bm{\lambda}_j^n,\bm{\hat u}_j^n) = \bm{H}(\bm\lambda)^{-1},
\end{align*}\end{linenomath*}
hence $\partial_{\bm{\hat u}} \bm{d}$ is a block diagonal matrix. Let us now look at $\partial_{\bm{\lambda}} \bm{c}$ at a fixed spatial cell $j$:
\begin{linenomath*}\begin{align*}
\frac{\partial \bm{c}}{\partial \bm{\lambda}_{\ell}}\frac{\partial \bm{d}(\bm{\lambda}_{j-1}^{n},\bm{\hat u}_{j-1}^{n})}{\partial \bm{\lambda}} = \bm{0},
\end{align*}\end{linenomath*}
since we already showed that by the choice of $\bm{H}(\bm\lambda)^{-1}$ the term $\partial_{\bm{\lambda}} \bm{d}$ is zero. We can show the same result for all spatial cells and all inputs of $\bm{c}$ analogously, hence $\partial_{\bm{\lambda}} \bm{c} = \bm{0}$. For the last block, we have that 
\begin{linenomath*}\begin{align*}
\frac{\partial \bm{c}}{\partial \bm{\lambda}_{\ell}}\frac{\partial \bm{d}(\bm{\lambda}_{j-1}^{n},\bm{\hat u}_{j-1}^{n})}{\partial \bm{\hat u}} = \frac{\partial \bm{c}}{\partial \bm{\lambda}_{\ell}} \bm{H}(\bm\lambda)^{-1} = \frac{\partial \bm{c}}{\partial \bm{\lambda}_{\ell}} \langle \nabla\bm{u}_s(\bm{\varphi}^T\bm{\lambda}_{j-1}^n)\bm{\varphi}\bm{\varphi}^T \rangle^{-T} = \partial_{\bm{\hat u}_{\ell}}\bm{\tilde c}_j
\end{align*}\end{linenomath*}
by the choice of $\bm{H}(\bm\lambda)^{-1}$ as well as \eqref{eq:cTildeDer} and \eqref{eq:dudlambdaex}. We obtain an analogous result for the second and third input. Hence, we have that $\partial_{\bm{\hat u}} \bm{c} = \nabla_{\bm{\hat u}}\bm{\tilde c}$, which only has eigenvalues between $-1$ and $1$ by the assumption that the classical IPM iteration is contractive. Since $\bm{J}$ is an upper triangular block matrix, the eigenvalues are given by $\lambda\left(\partial_{\bm{\lambda}} \bm{d}\right) = 0$ and $\lambda\left(\partial_{\bm{\hat u}} \bm{c}\right)\in(-1,1)$, hence the One-Shot IPM is contractive around its fixed point.
\end{proof}
\begin{theorem}\label{th:localConvergence}
With the assumptions from Theorem \ref{th:Contractive}, the One-Shot IPM converges locally, i.e. there exists a $\delta>0$ s.t. for all starting points $(\bm{\lambda}^0,\bm{\hat u}^0)\in B_{\delta}(\bm{\lambda}^*,\bm{\hat u}^*)$ we have
\begin{linenomath*}\begin{align*}
\Vert (\bm{\lambda}^n,\bm{\hat u}^n) - (\bm{\lambda}^*,\bm{\hat u}^*)\Vert \rightarrow 0 \qquad \text{ for } n \rightarrow \infty.
\end{align*}\end{linenomath*}
\end{theorem}
\begin{proof}
By Theorem \ref{th:Contractive}, the One-Shot scheme is contractive at its fixed point. Since we assumed convergence of the classical IPM scheme, we can conclude that all entries in the Jacobian $\bm{J}$ are continuous functions. Furthermore, the determinant of $\bm{\tilde{J}}:=\bm{J}-\lambda \bm{I}_d$ is a polynomial of continuous functions, since
\begin{linenomath*}\begin{align*}
\text{det}(\bm{\tilde J}) = \sum_{\sigma} \text{sgn}(\sigma)\prod_{i = 1}^{2 N_x N} \tilde J_{\sigma(i),i}.
\end{align*}\end{linenomath*}
Since the roots of a polynomial vary continuously with its coefficients, the eigenvalues of $\bm{J}$ are continuous w.r.t $(\bm{\lambda},\bm{\hat u})$. Hence there exists an open ball with radius $\delta$ around the fixed point in which the eigenvalues remain in the interval $(-1,1)$.
\end{proof}
%\begin{remark}
%Since the preconditioning step of the Collocation-accelerated IPM method generates initial conditions which are close to the steady state solution, using One-Shot IPM instead of classical IPM is well suited. However, our numerical calculations show that One-Shot IPM converges even if the solution is far away from its steady state. 
%\end{remark}